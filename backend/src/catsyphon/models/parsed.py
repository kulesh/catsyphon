"""
Parsed conversation data models.

These are intermediate Python dataclasses representing parsed conversations
before they are stored in the database. Used by parsers and the ingestion pipeline.
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional


@dataclass
class ToolCall:
    """Tool invocation by agent."""

    tool_name: str
    parameters: dict
    result: Optional[str] = None
    success: bool = True
    timestamp: Optional[datetime] = None


@dataclass
class CodeChange:
    """Code modification."""

    file_path: str
    change_type: str  # 'create', 'edit', 'delete'
    old_content: Optional[str] = None
    new_content: Optional[str] = None
    lines_added: int = 0
    lines_deleted: int = 0


@dataclass
class ParsedMessage:
    """Single message in a conversation."""

    role: str  # 'user', 'assistant', 'system'
    content: str
    timestamp: datetime
    tool_calls: list[ToolCall] = field(default_factory=list)
    code_changes: list[CodeChange] = field(default_factory=list)
    entities: dict = field(default_factory=dict)
    model: Optional[str] = None  # Claude model used (for assistant messages)
    token_usage: Optional[dict] = None  # Token usage statistics
    thinking_content: Optional[str] = None  # Extended thinking blocks (Claude)


@dataclass
class ParsedConversation:
    """Unified format for all parsed conversations."""

    agent_type: str
    agent_version: Optional[str]
    start_time: datetime
    end_time: Optional[datetime]
    messages: list[ParsedMessage]
    metadata: dict = field(default_factory=dict)
    session_id: Optional[str] = None  # Unique session identifier
    git_branch: Optional[str] = None  # Git branch during conversation
    working_directory: Optional[str] = None  # Working directory path
    files_touched: list[str] = field(default_factory=list)  # List of file paths
    code_changes: list[CodeChange] = field(default_factory=list)  # Code modifications

    # Hierarchy fields (Phase 2: Epic 7u2)
    conversation_type: str = "main"  # 'main', 'agent', 'mcp', 'skill', 'command', 'other'
    parent_session_id: Optional[str] = None  # Parent session ID for agent/tool conversations
    context_semantics: dict = field(default_factory=dict)  # Context sharing behavior
    agent_metadata: dict = field(default_factory=dict)  # Agent-specific metadata


@dataclass
class ConversationTags:
    """Tags generated by the tagging engine."""

    # Sentiment
    sentiment: Optional[str] = None
    sentiment_score: Optional[float] = None

    # Classification
    intent: Optional[str] = None
    outcome: Optional[str] = None

    # Iteration tracking
    iterations: int = 1

    # Extracted entities
    entities: dict = field(default_factory=dict)

    # Features and problems
    features: list[str] = field(default_factory=list)
    problems: list[str] = field(default_factory=list)
    patterns: list[str] = field(default_factory=list)

    # Tools used
    tools_used: list[str] = field(default_factory=list)
    has_errors: bool = False

    # LLM reasoning (why these tags were assigned)
    reasoning: Optional[str] = None

    def to_dict(self) -> dict:
        """Convert to dictionary for storage in JSONB."""
        return {
            "sentiment": self.sentiment,
            "sentiment_score": self.sentiment_score,
            "intent": self.intent,
            "outcome": self.outcome,
            "iterations": self.iterations,
            "entities": self.entities,
            "features": self.features,
            "problems": self.problems,
            "patterns": self.patterns,
            "tools_used": self.tools_used,
            "has_errors": self.has_errors,
            "reasoning": self.reasoning,
        }
