# Skill-Based Analytics Product Specification

Status: Draft  
Owner: Product + Platform Engineering  
Last updated: 2026-02-12

## 1. Executive Summary

CatSyphon will transition from hardcoded analytics features to a skill-native analytics platform.

Today, analytics capabilities such as Weekly Digest, AI Insights, and dashboard modules are implemented as application code. In the target model, all analytics logic is represented as versioned skills executed by a governed runtime. CatSyphon ships default skill packs and allows workspace-specific extension through custom skills.

This is a product model change, not only a technical refactor:

- Analytics capabilities become configurable product assets.
- Skill definitions become versioned domain entities.
- Correctness and safety are enforced through contracts, certification gates, and lineage.

## 2. Problem Statement

Current analytics delivery has four structural limits:

1. Product iteration bottleneck
Analytics changes require code changes, deployment, and backend/frontend release coordination.

2. Limited tenant customization
Teams cannot adapt insights, scoring logic, or digest composition to their operating model without forking behavior in code.

3. Weak provenance and explainability
Users see analytics output but cannot reliably inspect which logic version produced it.

4. Expensive feature growth
Each new digest section or insight card increases code surface area and long-term maintenance.

## 3. Vision

CatSyphon becomes the analytics control plane for AI coding telemetry:

- Built-in curated skills provide immediate value out of the box.
- Workspaces can install and configure additional skill packs.
- Every artifact (digest, insight, card, recommendation) is generated by a named skill version with explicit lineage.
- Correctness is enforced with typed input/output contracts, deterministic operators, and certification workflows.

## 4. Goals and Non-Goals

## 4.1 Goals

1. Make all analytics and digest capabilities skill-driven.
2. Preserve or improve correctness, explainability, and reproducibility.
3. Enable safe, governed customization per workspace.
4. Support production lifecycle for skills: draft, test, certify, promote, rollback.
5. Preserve UI continuity during migration.

## 4.2 Non-Goals (v1)

1. Arbitrary user code execution in-process.
2. Unrestricted network/file system access from skills.
3. Full replacement of ingestion/parsing engines with skills.
4. Multi-language skill runtimes beyond declarative DSL and approved operators.

## 5. Product Principles

1. Trusted kernel, extensible logic
Runtime, policy enforcement, and semantic layer remain code-based and trusted.

2. Declarative first
Skills define intent via manifests and operator graphs, not arbitrary scripts.

3. Correctness before flexibility
A skill cannot reach production without schema and certification checks.

4. Immutable versions
Skill versions are immutable and addressable.

5. Full provenance
Every artifact references skill ID/version, data snapshot window, and execution metadata.

## 6. User Personas and Jobs To Be Done

## 6.1 Workspace Admin

Jobs:

- Install/enable default or custom skill packs.
- Configure schedules and policies.
- Approve promotion of skill versions.

Success criteria:

- Can adopt new analytics behavior without app deploy.
- Can rollback quickly when behavior is incorrect.

## 6.2 Engineering Manager

Jobs:

- Customize metrics and weekly digest composition to team process.
- Compare outputs over time with confidence in consistency.

Success criteria:

- Receives reliable, auditable insights tailored to team goals.

## 6.3 Analyst/Power User

Jobs:

- Define domain-specific analytics capabilities.
- Validate skill outputs against expected test fixtures.

Success criteria:

- Ships skills safely without backend code changes.

## 7. Scope

In scope:

- Skill-native Weekly Digest.
- Skill-native AI Insights cards and recommendation blocks.
- Skill-native dashboard modules and periodic analytics jobs.
- Built-in skill pack shipping with CatSyphon.
- Workspace-managed custom skill installation/configuration.

Out of scope:

- Arbitrary plugin code execution.
- Non-governed ad hoc SQL from untrusted users.

## 8. Domain Model Changes

Skill platform introduces new first-class entities.

## 8.1 Aggregates

1. Skill
- Stable identity, owner, purpose, capabilities envelope.

2. SkillVersion
- Immutable definition payload, semantic version, compatibility constraints.

3. SkillBinding
- Binds a skill version (or channel alias) to a product surface:
  - Dashboard card
  - Digest section
  - Insight module
  - Scheduled report

4. SkillRun
- One execution instance with start/end timestamps, status, costs, and lineage.

5. SkillArtifact
- Typed output for UI/exports (json, markdown, chart spec, table spec).

6. SkillCertification
- Validation and approval record for production eligibility.

7. SkillSchedule
- Cron/interval schedule for automated runs.

8. SkillCapabilityPolicy
- Defines allowed operators and data access scope.

## 8.2 Ubiquitous Language

- Capability: What a skill is allowed to do.
- Contract: Typed input/output schema and compatibility promises.
- Certification: A successful quality gate record for a skill version.
- Promotion: Move skill version from draft/staging to production.
- Provenance: Full metadata linking artifact to logic, inputs, and runtime context.

## 9. Skill Definition Model

Skills are declarative documents with:

1. Metadata
- `skill_id`, `name`, `description`, `owner`, `version`.

2. Interface
- Input schema (time range, workspace scope, options).
- Output schema (artifact payload contract).

3. Capability declaration
- Allowed datasets/views.
- Allowed operators.
- LLM usage policy (optional).

4. Execution graph
- Ordered operators with explicit inputs/outputs.
- Deterministic operator boundaries and optional nondeterministic stages (LLM).

5. Tests
- Golden fixtures, expected assertions, tolerances.

6. Release metadata
- Compatibility bounds and migration notes.

## 10. Runtime and Execution Semantics

## 10.1 Runtime Responsibilities

1. Parse and validate skill manifests.
2. Enforce capability policies.
3. Resolve data contracts and semantic metrics.
4. Execute operator graph with retries and idempotency keys.
5. Persist run metadata and artifacts.
6. Emit telemetry and audit events.

## 10.2 Execution Guarantees

1. Skill version immutability.
2. At-least-once job execution with idempotent run key support.
3. Bounded runtime and memory quotas.
4. Strong provenance capture on success and failure.

## 10.3 Supported Operator Classes (v1)

1. Query operators
- Read from approved semantic views only.

2. Transform operators
- Filter, join, group, rank, bucket, map.

3. Scoring operators
- Deterministic calculations on typed inputs.

4. Summarization operators
- LLM-based summarization constrained by schema and prompt templates.

5. Render operators
- Generate typed artifact payloads for UI surfaces.

## 11. Correctness and Quality Enforcement

Correctness must be platform-level policy, not a best effort.

## 11.1 Contract Enforcement

1. Input schema validation before run start.
2. Output schema validation before artifact publish.
3. Strict version compatibility checks for data contracts.

## 11.2 Certification Pipeline

A skill version reaches production only if:

1. Static validation passes.
2. Unit fixture tests pass.
3. Regression comparison checks pass against baseline.
4. Cost and latency budgets pass.
5. Owner/admin approval recorded.

## 11.3 Reproducibility

Every run stores:

- Skill ID/version digest.
- Data window and query fingerprints.
- Operator runtime versions.
- Model identifiers (if LLM used).
- Environment metadata.

## 11.4 Guardrails

1. Deterministic mode required for score-critical skills.
2. Tolerance bands for metric deltas.
3. Fallback behavior on operator failures (graceful degradation).

## 12. Security and Governance Model

## 12.1 Capability-Based Access

Skills receive explicit capabilities:

1. Data scopes (workspace/project-level).
2. Operator permissions.
3. LLM access level and token budget.
4. Output channels allowed for publishing.

## 12.2 Isolation

1. No arbitrary code execution in v1.
2. No direct host file system or shell access.
3. No unrestricted external network calls from skill logic.

## 12.3 Auditability

Audit events are mandatory for:

- Install/uninstall.
- Config changes.
- Promotion/rollback.
- Manual or scheduled runs.
- Policy denials and runtime failures.

## 13. Product Surfaces and UX

## 13.1 Skill Catalog

Capabilities:

1. Browse built-in and installed skill packs.
2. View metadata, contracts, and certification status.
3. Enable/disable skills per workspace.

## 13.2 Skill Lifecycle UI

Capabilities:

1. Draft configuration.
2. Test run with fixture and live preview.
3. Certification results.
4. Promote/rollback controls.

## 13.3 Analytics Surfaces

Dashboard cards, Weekly Digest, and AI Insights display:

1. Artifact payload.
2. Provenance badge (`skill_id@version`).
3. Last run status and freshness.

## 14. API and Integration Requirements

## 14.1 Core APIs

1. Skill CRUD + version management.
2. Skill validation and test execution.
3. Run execution (sync trigger + async job).
4. Artifact retrieval and historical versions.
5. Promotion and rollback endpoints.

## 14.2 Backward-Compatible Facades

Existing digest/insight endpoints continue to function but route internally through bound skills during migration.

## 15. Data Model and Storage Requirements

Required new tables:

1. `skills`
2. `skill_versions`
3. `skill_bindings`
4. `skill_runs`
5. `skill_artifacts`
6. `skill_certifications`
7. `skill_schedules`
8. `skill_capability_policies`

Existing analytics entities remain source-of-truth telemetry and semantic facts.

## 16. Observability and SLOs

## 16.1 Required Telemetry

1. Run latency per skill.
2. Success/failure rate.
3. Operator-level error rates.
4. LLM usage/cost metrics.
5. Artifact freshness lag.

## 16.2 Initial SLO Targets

1. Skill runtime success rate >= 99.0% (excluding invalid definitions).
2. Digest generation freshness <= 15 minutes from schedule.
3. Certification checks complete <= 5 minutes for standard skills.

## 17. Migration Strategy

1. Wrap existing Weekly Digest and AI Insights logic as internal skill versions.
2. Add bindings from current UI surfaces to internal skills.
3. Add provenance and certification visibility.
4. Open custom skill installation only after policy/certification gates are live.
5. Remove hardcoded analytics pathways once parity and stability are met.

## 18. Risks and Mitigations

1. Metric drift across skills
Mitigation: semantic layer contracts + deterministic operators.

2. Runtime cost explosion
Mitigation: capability budgets, quotas, and per-skill cost alerts.

3. Skill sprawl and governance debt
Mitigation: lifecycle states, ownership requirements, deprecation policy.

4. User trust erosion from inconsistent outputs
Mitigation: certification, provenance, and rollback semantics.

## 19. Success Metrics

1. Percentage of analytics surfaces powered by skill bindings.
2. Time-to-ship new analytics capability (median).
3. Number of workspace-customized analytics capabilities in active use.
4. Reduction in analytics-related backend code churn.
5. Accuracy and trust indicators from user feedback and support tickets.

## 20. Open Questions

1. Should custom skills be workspace-local only in v1, or org-shareable?
2. What is the exact DSL shape for operator graphs and templates?
3. Which existing metrics become semantic layer canon vs optional skill-level derivation?
4. What review model is required for production promotion in enterprise mode?
5. Which LLM providers/models are allowed per capability policy tier?

